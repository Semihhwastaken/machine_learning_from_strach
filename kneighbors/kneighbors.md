# 1. K-Neighbors Classifier Nedir?
K-Neighbors Classifier (KNN), temelinde Ã¶rnek tabanlÄ± Ã¶ÄŸrenme yÃ¶ntemlerinden biridir. Yani, KNN modeli eÄŸitim sÄ±rasÄ±nda herhangi bir Ã¶ÄŸrenme iÅŸlemi yapmaz. Bunun yerine, tÃ¼m eÄŸitim verilerini bellekte saklar ve bir test Ã¶rneÄŸi geldiÄŸinde bu Ã¶rneÄŸi komÅŸularÄ±yla karÅŸÄ±laÅŸtÄ±rarak bir tahmin yapar.

KÄ±sacasÄ±:
- EÄŸitim sÄ±rasÄ±nda sadece verileri saklar.
- Tahmin yaparken, bir test Ã¶rneÄŸini eÄŸitim veri kÃ¼mesindeki en yakÄ±n k komÅŸusuyla kÄ±yaslar.
- Ã‡oÄŸunluÄŸa dayalÄ± bir karar verir

# 2. NasÄ±l Ã‡alÄ±ÅŸÄ±r?
KNN algoritmasÄ± ÅŸu adÄ±mlarla Ã§alÄ±ÅŸÄ±r:

### 1. Mesafe Ã–lÃ§Ã¼mÃ¼
KNN, test Ã¶rneÄŸi ile eÄŸitim verisindeki her Ã¶rnek arasÄ±ndaki mesafeyi hesaplar. En sÄ±k kullanÄ±lan mesafe Ã¶lÃ§Ã¼mleri ÅŸunlardÄ±r:

- Ã–klid Mesafesi (ğ¿2 normu):

$$d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$$

- Manhattan Mesafesi (ğ¿1 normu):

$$d(x,y) = \sum_{i=1}^n |x_i - y_i|$$

- Minkowski Mesafesi (ğ¿p normu):

$$d(x,y) = (\sum_{i=1}^n |x_i - y_i|^p)^{\frac{1}{p}}$$

### 2. KomÅŸularÄ± Belirleme
TÃ¼m mesafeler hesaplandÄ±ktan sonra, en kÃ¼Ã§Ã¼k mesafeye sahip k adet komÅŸu seÃ§ilir. Bu komÅŸular test Ã¶rneÄŸine en yakÄ±n olan eÄŸitim Ã¶rnekleridir.

### 3. Tahmin Yapma
SÄ±nÄ±flandÄ±rma: SeÃ§ilen k komÅŸunun sÄ±nÄ±flarÄ±na bakÄ±lÄ±r ve Ã§oÄŸunluÄŸun sÄ±nÄ±fÄ± test Ã¶rneÄŸi iÃ§in tahmin edilir.
Regresyon: SeÃ§ilen k komÅŸunun etiket deÄŸerlerinin ortalamasÄ± alÄ±nÄ±r.

# 3. Hiperparametreler
KNN algoritmasÄ±nda, birkaÃ§ Ã¶nemli hiperparametre vardÄ±r:

### 1. k (KomÅŸu SayÄ±sÄ±):
- k, test Ã¶rneÄŸi iÃ§in kaÃ§ komÅŸunun dikkate alÄ±nacaÄŸÄ±nÄ± belirtir.
- KÃ¼Ã§Ã¼k bir k: Model daha esnek olur, ama gÃ¼rÃ¼ltÃ¼ye duyarlÄ± hale gelir (overfitting).
- BÃ¼yÃ¼k bir k: Model daha kararlÄ± hale gelir, ama genel yapÄ±yÄ± kaÃ§Ä±rabilir (underfitting).

### 2. Mesafe Ã–lÃ§Ã¼tÃ¼:
- KullanÄ±lan mesafe Ã¶lÃ§Ã¼tÃ¼ modelin baÅŸarÄ±sÄ±nÄ± doÄŸrudan etkiler. Ã–rneÄŸin:
- Ã–klid mesafesi genelde daha yaygÄ±ndÄ±r.
- Manhattan mesafesi, Ã¶zelliklerin Ã¶lÃ§eklendirilmesi durumunda daha kararlÄ± olabilir.

### 3. AÄŸÄ±rlÄ±klandÄ±rma:
- KNN, komÅŸularÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± mesafeye gÃ¶re ayarlayabilir.
- Uniform: TÃ¼m komÅŸular eÅŸit aÄŸÄ±rlÄ±k alÄ±r.
- Distance-weighted: Daha yakÄ±n komÅŸulara daha fazla aÄŸÄ±rlÄ±k verilir.

# 4. AvantajlarÄ± ve DezavantajlarÄ±
### AvantajlarÄ±:
- Basit ve Sezgisel: Ã‡ok az matematiksel karmaÅŸÄ±klÄ±k iÃ§erir.
- EÄŸitim SÃ¼resi Ã‡ok HÄ±zlÄ±dÄ±r: Model oluÅŸtururken sadece veriler saklanÄ±r.
- Ã‡ok YÃ¶nlÃ¼: Hem sÄ±nÄ±flandÄ±rma hem de regresyonda kullanÄ±labilir.

### DezavantajlarÄ±:
- Tahmin SÃ¼resi YavaÅŸ: Her tahminde tÃ¼m veri kÃ¼mesini dolaÅŸÄ±r, bu da bÃ¼yÃ¼k veri kÃ¼melerinde yavaÅŸtÄ±r.
- Bellek TÃ¼ketimi YÃ¼ksek: EÄŸitim verisinin tamamÄ±nÄ± saklamak gerekir.
- Ã–zellik Ã–lÃ§eklendirmesi Gerektirir: Mesafeler Ã¶zelliklerin Ã¶lÃ§eÄŸine duyarlÄ± olduÄŸundan, verilerin standartlaÅŸtÄ±rÄ±lmasÄ± Ã¶nemlidir.
- GÃ¼rÃ¼ltÃ¼ye DuyarlÄ±: GÃ¼rÃ¼ltÃ¼lÃ¼ veriler kÃ¼Ã§Ã¼k k deÄŸerlerinde hatalÄ± tahminlere yol aÃ§abilir.

# 5. Python ile KNN UygulamasÄ±

```python
class KNeighborsClassifier:
    def __init__(self, n_neighbors=5):
        self.n_neighbors = n_neighbors
        self.X_train = None
        self.y_train = None
    
    def fit(self, X, y):
        """EÄŸitim verilerini saklar"""
        self.X_train = X
        self.y_train = y
```
### 1. __init__ metodu
    Bu metod, sÄ±nÄ±fÄ±n baÅŸlatÄ±cÄ± metodudur ve sÄ±nÄ±fÄ±n bir Ã¶rneÄŸi oluÅŸturulduÄŸunda otomatik olarak Ã§alÄ±ÅŸÄ±r. Bu metodda:
        - n_neighbors: KullanÄ±cÄ±ya komÅŸu sayÄ±sÄ±nÄ± belirleme ÅŸansÄ± tanÄ±r. EÄŸer kullanÄ±cÄ± bir deÄŸer girmezse, varsayÄ±lan olarak 5 komÅŸu kullanÄ±lÄ±r.
        - X_train ve y_train: EÄŸitim verilerini saklayacak boÅŸ deÄŸiÅŸkenlerdir. EÄŸitim sÃ¼reci baÅŸladÄ±ÄŸÄ±nda bu verilere deÄŸer atanacaktÄ±r.

### 2. fit metodu
    Bu metod, modeli eÄŸitmek iÃ§in kullanÄ±lan metoddur. KNN algoritmasÄ± model eÄŸitimi sÄ±rasÄ±nda hiÃ§bir karmaÅŸÄ±k hesaplama yapmaz, Ã§Ã¼nkÃ¼ KNN bir instance-based (Ã¶rnek tabanlÄ±) algoritmadÄ±r.
        - EÄŸitim Verilerinin SaklanmasÄ±: Bu adÄ±mda, gelen eÄŸitim verisi (Ã¶zellikler ve etiketler) modelin belleÄŸine kaydedilir.
        - self.X_train: EÄŸitim Ã¶zellikleri (Ã¶zellikler matrisi).
        - self.y_train: EÄŸitim etiketleri (etiketler vektÃ¶rÃ¼).

```python
def _euclidean_distance(self, x1, x2):
        """Ä°ki nokta arasÄ±ndaki Ã–klid mesafesini hesaplar"""
        distance = 0
        for i in range(len(x1)):
            distance += (x1[i] - x2[i]) ** 2
        return distance ** 0.5
```

### 3. _euclidean_distance metodu
```python

    def _euclidean_distance(self, x1, x2):
        """Ä°ki nokta arasÄ±ndaki Ã–klid mesafesini hesaplar"""
        distance = 0
        for i in range(len(x1)):
            distance += (x1[i] - x2[i]) ** 2
        return distance ** 0.5
```
    Bu metod, Ã–klid mesafesi hesaplamak iÃ§in kullanÄ±lÄ±r. Ä°ki nokta arasÄ±ndaki mesafeyi hesaplar, genellikle KNN algoritmasÄ±nda komÅŸularÄ±n yakÄ±nlÄ±k derecelerini belirlemek iÃ§in kullanÄ±lÄ±r.

### 4. _get_neighbors metodu
```python
    def _get_neighbors(self, test_sample):
        """Test Ã¶rneÄŸi iÃ§in en yakÄ±n k komÅŸuyu bulur"""
        distances = []
        for i, train_sample in enumerate(self.X_train):
            dist = self._euclidean_distance(test_sample, train_sample)
            distances.append((dist, self.y_train[i]))
        
        # Mesafelere gÃ¶re sÄ±rala ve en yakÄ±n k komÅŸuyu al
        distances.sort(key=lambda x: x[0])
        return [d[1] for d in distances[:self.n_neighbors]]
```
    Bu metod, verilen bir test Ã¶rneÄŸi iÃ§in en yakÄ±n k komÅŸuyu bulur. KNN algoritmasÄ±nda tahmin yaparken, en yakÄ±n k komÅŸunun sÄ±nÄ±flarÄ± kullanÄ±lÄ±r. Bu adÄ±m ÅŸu ÅŸekilde iÅŸler:

        - test_sample: Bu, tahmin yapÄ±lacak test Ã¶rneÄŸidir.
        - Mesafelerin HesaplanmasÄ±: EÄŸitim veri kÃ¼mesindeki her bir Ã¶rnek ile test Ã¶rneÄŸi arasÄ±ndaki Ã–klid mesafesi hesaplanÄ±r.
        - Mesafelerle BirleÅŸtirilmiÅŸ Etiketler: Her mesafe ile ilgili etiket, mesafelerin bir listesini oluÅŸturur. Yani her bir mesafe ile birlikte hangi sÄ±nÄ±fa ait olduÄŸu bilgisi tutulur.
        - KomÅŸu SeÃ§imi: Mesafeler sÄ±ralanÄ±r ve en kÃ¼Ã§Ã¼k k mesafeye sahip komÅŸular seÃ§ilir.
        - Bu metodun amacÄ±, test Ã¶rneÄŸi iÃ§in en yakÄ±n k komÅŸuyu bulmaktÄ±r.

### 5. predict metodu
```python
    def predict(self, X):
        """Test Ã¶rnekleri iÃ§in tahminlerde bulunur"""
        predictions = []
        for test_sample in X:
            neighbors = self._get_neighbors(test_sample)
            # En sÄ±k gÃ¶rÃ¼len sÄ±nÄ±fÄ± bul
            prediction = max(set(neighbors), key=neighbors.count)
            predictions.append(prediction)
        return predictions
```
    Bu metod, modelin tahmin yapma iÅŸlevini yerine getirir.
    - Test Verisi Ãœzerinde Tahmin: Bu metot, birden fazla test Ã¶rneÄŸi alabilir (yani bir veri kÃ¼mesi) ve her bir Ã¶rnek iÃ§in tahmin yapar.
    - KomÅŸu SeÃ§imi: Her bir test Ã¶rneÄŸi iÃ§in _get_neighbors metodu Ã§aÄŸrÄ±lÄ±r ve en yakÄ±n k komÅŸu bulunur.
    - SÄ±nÄ±f Tahmini: En yakÄ±n k komÅŸusunun sÄ±nÄ±flarÄ±na bakÄ±lÄ±r ve bu sÄ±nÄ±flar arasÄ±nda Ã§oÄŸunluÄŸu belirlenir (en sÄ±k gÃ¶rÃ¼len sÄ±nÄ±f seÃ§ilir).
    - En sÄ±k gÃ¶rÃ¼len sÄ±nÄ±f, test Ã¶rneÄŸi iÃ§in yapÄ±lan tahmindir. Python'da bunun iÃ§in max(set(neighbors), key=neighbors.count) kullanÄ±lÄ±r. Bu, komÅŸularÄ±n sÄ±nÄ±f sayÄ±sÄ±nÄ± sayar ve en fazla gÃ¶rÃ¼len sÄ±nÄ±fÄ± seÃ§er.

