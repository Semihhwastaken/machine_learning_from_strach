```python
class RidgeRegression:
    def __init__(self, alpha=1.0, max_iter=1000, tol=1e-4):
        self.alpha = alpha  # regularizasyon parametresi
        self.max_iter = max_iter  # maksimum iterasyon sayÄ±sÄ±
        self.tol = tol  # tolerans deÄŸeri
        self.weights = None
        self.bias = None
```
`alpha (Regularization Parameter)`
    TanÄ±m: alpha Ridge Regression iÃ§in Ã§ok Ã¶nemli bir parametredir. Bu, modelde kullanÄ±lan regularization (dÃ¼zenleme) gÃ¼cÃ¼nÃ¼ kontrol eder.

    AmaÃ§: EÄŸer yalnÄ±zca doÄŸruluk odaklÄ± bir model eÄŸitirsek, model tÃ¼m veriyi "ezberleyebilir". Buna overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme) denir.
    Regularization, modelin aÄŸÄ±rlÄ±klarÄ±nÄ± biraz "kÄ±sÄ±tlayarak" bu aÅŸÄ±rÄ± Ã¶ÄŸrenmenin Ã¶nÃ¼ne geÃ§er.
    alpha bu kÄ±sÄ±tlamanÄ±n ne kadar gÃ¼Ã§lÃ¼ olduÄŸunu belirler.

`max_iter (Maximum Iteration)`
    TanÄ±m: Gradyan iniÅŸi (gradient descent) gibi optimizasyon yÃ¶ntemlerinde, model aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncellerken belirli bir sayÄ±da iterasyon yapÄ±lÄ±r. max_iter, bu sÃ¼recin maksimum kaÃ§ kez tekrar edileceÄŸini belirler.

    AmaÃ§: EÄŸer model istenilen Ã§Ã¶zÃ¼mÃ¼ bulamÄ±yorsa (Ã¶rneÄŸin, eÄŸri dÃ¼zgÃ¼n oturmuyorsa), bu sayede bir durdurma kriterimiz olur. Sonsuza kadar Ã§alÄ±ÅŸmaz!

`tol (Tolerance)`
    TanÄ±m: Bu, yakÄ±nsama kontrolÃ¼ iÃ§in bir eÅŸik deÄŸeridir. Modelin aÄŸÄ±rlÄ±klarÄ± (weights) ve bias'Ä± gÃ¼ncellenirken, her bir iterasyondaki deÄŸiÅŸim Ã§ok kÃ¼Ã§Ã¼k bir deÄŸerin altÄ±na dÃ¼ÅŸtÃ¼ÄŸÃ¼nde eÄŸitim durdurulur.

    AmaÃ§: Bu tolerans deÄŸeri, modelin ne zaman yeterince iyi bir Ã§Ã¶zÃ¼m bulduÄŸunu anlamak iÃ§in kullanÄ±lÄ±r. BÃ¶ylece gereksiz iterasyonlardan kaÃ§Ä±nÄ±rÄ±z.

```python
def _normalize(self, X):
        # Ã–zellikleri normalize et
        means = [sum(col) / len(col) for col in zip(*X)]
        stds = [sum((x - m) ** 2 for x in col) ** 0.5 / len(col) ** 0.5 
               for col, m in zip(zip(*X), means)]
        X_norm = [[(x - m) / s if s != 0 else 0 
                   for x, m, s in zip(row, means, stds)] 
                  for row in X]
        return X_norm, means, stds
```
`sum(col) / len(col)` -> TÃ¼m sÃ¼tunlarÄ±n ortalamasÄ±nÄ± alÄ±r.
`sum((x - m) ** 2 for x in col) ** 0.5 / len(col) ** 0.5` -> TÃ¼m sÃ¼tunlarÄ±n standart sapmasÄ±nÄ± alÄ±r.
`X_norm = [[(x - m) / s if s != 0 else 0 `
                   `for x, m, s in zip(row, means, stds)] `
                  `for row in X]` -> TÃ¼m sÃ¼tunlarÄ± normalize eder.

`Normalizasyon Nedir?`

Normalizasyon, verileri belirli bir Ã¶lÃ§eÄŸe dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemidir. Ã–rneÄŸin, tÃ¼m Ã¶zelliklerin ortalamasÄ±nÄ± 0, standart sapmasÄ±nÄ± 1 yapabilirsiniz.
Normalizasyonun amacÄ±, her Ã¶zelliÄŸin model Ã¼zerinde eÅŸit aÄŸÄ±rlÄ±ÄŸa sahip olmasÄ±nÄ± saÄŸlamaktÄ±r. Ã–zellikle doÄŸrusal modeller (Ã¶rneÄŸin Ridge veya Lasso) ve gradient tabanlÄ± yÃ¶ntemlerde (Ã¶rneÄŸin SGD) bu Ã¶nemlidir.

```python
def fit(self, X, y):
        # Veriyi normalize et
        X_norm, self.means, self.stds = self._normalize(X)
        n_samples = len(X)
        n_features = len(X[0])
        
        # AÄŸÄ±rlÄ±klarÄ± ve bias'Ä± baÅŸlat
        self.weights = [0.0] * n_features
        self.bias = 0.0
        
        # Gradyan iniÅŸi
        for _ in range(self.max_iter):
            weights_old = self.weights.copy()
            
            # Her Ã¶rnek iÃ§in gradyanlarÄ± hesapla
            for i in range(n_samples):
                # Tahmin
                y_pred = sum(w * x for w, x in zip(self.weights, X_norm[i])) + self.bias
                
                # Hata
                error = y_pred - y[i]
                
                # AÄŸÄ±rlÄ±klarÄ± gÃ¼ncelle
                for j in range(n_features):
                    self.weights[j] -= (2 * error * X_norm[i][j] + 
                                      2 * self.alpha * self.weights[j]) / n_samples
                
                # Bias'Ä± gÃ¼ncelle
                self.bias -= 2 * error / n_samples
            
            # YakÄ±nsama kontrolÃ¼
            if all(abs(w - w_old) < self.tol 
                  for w, w_old in zip(self.weights, weights_old)):
                break
```
# Ridge Regresyon Nedir?
    Ridge regresyon, doÄŸrusal regresyonun bir Ã§eÅŸididir ve overfitting problemini Ã¶nlemek iÃ§in modelin aÄŸÄ±rlÄ±k parametrelerine bir ceza (ğ¿2-norm) ekler. Ridge regresyonun optimizasyon problemi ÅŸu ÅŸekildedir:

    KayÄ±p fonksiyonu:
$$J(w,b) = \frac{1}{m} \sum_{i=1}^m (h_{w,b}(x^{(i)}) - y^{(i)})^2 + \alpha\|w\|^2$$

    Tahmin fonksiyonu:
$$h_{w,b}(x) = w^{\top}x + b$$

    AÃ§Ä±k hali:
$$h_{w,b}(x^{(i)}) = w_1x_1^{(i)} + w_2x_2^{(i)} + ... + w_nx_n^{(i)} + b$$

    Yani kayÄ±p fonksiyonu ÅŸu ÅŸekilde aÃ§Ä±lÄ±r:
$$J(w,b) = \frac{1}{m} \sum_{i=1}^m (w_1x_1^{(i)} + w_2x_2^{(i)} + ... + w_nx_n^{(i)} + b - y^{(i)})^2 + \alpha(w_1^2 + w_2^2 + ... + w_n^2)$$

    Burada:
- $J(w,b)$: KayÄ±p fonksiyonu
- $\|w\|^2 = \sum_{j=1}^d w_j^2$: L2-norm ceza terimi
- $\alpha$: Ceza teriminin aÄŸÄ±rlÄ±ÄŸÄ±nÄ± belirleyen hiperparametre


# Kodun MantÄ±ÄŸÄ±
                        self.weights = [0.0] * n_features
                        self.bias = 0.0
    
    AÄŸÄ±rlÄ±klar (ğ‘¤): Her Ã¶zelliÄŸin katsayÄ±sÄ±nÄ± tutar. Ä°lk baÅŸta hepsi 0.0 olarak baÅŸlatÄ±lÄ±r.
    Bias (ğ‘): Tahmin fonksiyonundaki sabit terim. Ä°lk baÅŸta 0.0 olarak baÅŸlatÄ±lÄ±r.

    Gradyan iniÅŸi, Ridge regresyonun kayÄ±p fonksiyonunu minimize etmek iÃ§in kullanÄ±lÄ±r. Kodun bu kÄ±smÄ± aÅŸaÄŸÄ±daki adÄ±mlardan oluÅŸur:

    Tahmin fonksiyonu:
$$y_{pred} = \sum_{j=1}^d w_jx_j + b$$
    Burada:
- $w_j$: AÄŸÄ±rlÄ±klar
- $x_j$: Girdinin normalize edilmiÅŸ Ã¶zellikleri

    Hata (error):
$$error = y_{pred} - y$$

    Gradyan iniÅŸi formÃ¼lÃ¼:
$$w_j \leftarrow w_j - \eta \frac{\partial J}{\partial w_j}$$

    Ridge Regresyon iÃ§in gradyan iniÅŸi formÃ¼lÃ¼:
$$\frac{\partial J}{\partial w_j} = \frac{2}{m} \left[\sum_{i=1}^m (y_{pred}^{(i)} - y^{(i)})x_j^{(i)}\right] + 2\alpha w_j$$

    Burada:
- $\frac{\partial J}{\partial w_j}$: J fonksiyonunun $w_j$'ye gÃ¶re kÄ±smi tÃ¼revi
- $m$: Ã¶rnek sayÄ±sÄ±
- $y_{pred}^{(i)}$: i. Ã¶rnek iÃ§in tahmin deÄŸeri
- $y^{(i)}$: i. Ã¶rnek iÃ§in gerÃ§ek deÄŸer
- $x_j^{(i)}$: i. Ã¶rneÄŸin j. Ã¶zelliÄŸi
- $\alpha$: regularizasyon parametresi
- $w_j$: j. aÄŸÄ±rlÄ±k

    Bias gÃ¼ncelleme formÃ¼lÃ¼:
$$\frac{\partial J}{\partial b} = \frac{2}{m} \sum_{i=1}^m (y_{pred}^{(i)} - y^{(i)})$$

    Burada:
- $\frac{\partial J}{\partial b}$: J fonksiyonunun b'ye gÃ¶re kÄ±smi tÃ¼revi
- $m$: Ã¶rnek sayÄ±sÄ±
- $y_{pred}^{(i)}$: i. Ã¶rnek iÃ§in tahmin deÄŸeri
- $y^{(i)}$: i. Ã¶rnek iÃ§in gerÃ§ek deÄŸer

# 	Regularizasyonun RolÃ¼

    Overfitting ve Underfitting:
    Ridge regresyonun Î± hiperparametresi overfitting ve underfitting arasÄ±nda denge kurar:
    ğ›¼ = 0: Ridge, klasik doÄŸrusal regresyona dÃ¶ner.
    ğ›¼ â†’ âˆ: TÃ¼m aÄŸÄ±rlÄ±klar sÄ±fÄ±ra yaklaÅŸÄ±r (underfitting).

    Ridge regresyonda aÄŸÄ±rlÄ±klar kÃ¼Ã§Ã¼ltÃ¼lÃ¼r, ancak tamamen sÄ±fÄ±rlanmaz.

# Hiperparametre SeÃ§imi (ğ›¼)
    Hiperparametre SeÃ§iminin Ã–nemi: Ridge regresyonda ğ›¼, modelin genel performansÄ±nÄ± etkiler.
    KÃ¼Ã§Ã¼k ğ›¼: Daha az ceza (overfitting riski artar).
    BÃ¼yÃ¼k ğ›¼: Daha fazla ceza (underfitting riski artar).

# Î± NasÄ±l SeÃ§ilir?
    Cross-validation (CV): Veri setini eÄŸitim ve doÄŸrulama kÄ±sÄ±mlarÄ±na bÃ¶lerek en iyi ğ›¼ deÄŸerini seÃ§ebilirsin.
    Grid Search: Ã‡eÅŸitli ğ›¼ deÄŸerlerini deneyip doÄŸrulama setindeki hatayÄ± minimize eden ğ›¼ deÄŸerini seÃ§ebilirsin.
    Bayesian Optimization veya Random Search: Hiperparametre optimizasyonu iÃ§in daha geliÅŸmiÅŸ yÃ¶ntemler.

# Gradyan iniÅŸi nedir?

    Gradyan iniÅŸi (Gradient Descent), makine Ã¶ÄŸreniminde optimizasyon problemlerini Ã§Ã¶zmek iÃ§in kullanÄ±lan en popÃ¼ler yÃ¶ntemlerden biridir. FarklÄ± gradyan iniÅŸi tÃ¼rleri, veri miktarÄ±na, problem boyutuna ve performans gereksinimlerine gÃ¶re tercih edilir. Ä°ÅŸte Gradient Descent Ã§eÅŸitleri ve bunlarÄ±n ayrÄ±ntÄ±lÄ± aÃ§Ä±klamalarÄ±:

## 1. Batch Gradient Descent (Tam YÄ±ÄŸÄ±n Gradyan Ä°niÅŸi)

    NasÄ±l Ã‡alÄ±ÅŸÄ±r?

    Gradyan, tÃ¼m veri seti (ğ‘‹ ve ğ‘¦) Ã¼zerinde hesaplanÄ±r.
    AÄŸÄ±rlÄ±klar, tÃ¼m veri setindeki hata fonksiyonunun gradyanÄ±na gÃ¶re gÃ¼ncellenir.
    Matematiksel FormÃ¼l:
$$w = w - \eta \cdot \nabla_w J(w)$$
    ğ‘¤: AÄŸÄ±rlÄ±k vektÃ¶rÃ¼.
    ğœ‚: Ã–ÄŸrenme oranÄ±.
    ğ½(ğ‘¤): TÃ¼m veri setindeki hata fonksiyonu.
    âˆ‡ğ‘¤ğ½(ğ‘¤): TÃ¼m veri seti Ã¼zerindeki gradyan.

    AvantajlarÄ±:
        Her gÃ¼ncellemede en doÄŸru gradyan bilgisi kullanÄ±lÄ±r.
        KararlÄ±dÄ±r ve daha iyi bir yakÄ±nsama saÄŸlar.

    DezavantajlarÄ±:
        BÃ¼yÃ¼k veri setlerinde hesaplama maliyeti yÃ¼ksektir (her adÄ±mda tÃ¼m veri setini tarar).
        Bellek tÃ¼ketimi fazladÄ±r.

## 2. Stochastic Gradient Descent (SGD) (Stokastik Gradyan Ä°niÅŸi)

    NasÄ±l Ã‡alÄ±ÅŸÄ±r?

    Gradyan, her bir veri Ã¶rneÄŸi iÃ§in hesaplanÄ±r ve aÄŸÄ±rlÄ±klar buna gÃ¶re gÃ¼ncellenir. Yani, her adÄ±mda tek bir veri Ã¶rneÄŸi kullanÄ±lÄ±r.
    Matematiksel FormÃ¼l:
$$w = w - \eta \cdot \nabla_w J(w; x_i, y_i)$$
    xi,yi: Tek bir veri Ã¶rneÄŸi.

    AvantajlarÄ±:
        BÃ¼yÃ¼k veri setlerinde daha hÄ±zlÄ±dÄ±r.
        Hesaplama maliyeti dÃ¼ÅŸÃ¼ktÃ¼r.
        Daha kolay bellek yÃ¶netimi (tek bir veri Ã¶rneÄŸi ile Ã§alÄ±ÅŸÄ±r).

    DezavantajlarÄ±:
        Hata fonksiyonu (loss) her adÄ±mda oldukÃ§a dalgalanÄ±r.
        Daha dÃ¼ÅŸÃ¼k doÄŸruluk veya yavaÅŸ yakÄ±nsama yaÅŸanabilir.
        YakÄ±nsama kontrolÃ¼ zor olabilir.

## 3. Mini-Batch Gradient Descent

    NasÄ±l Ã‡alÄ±ÅŸÄ±r?

    TÃ¼m veri setini kÃ¼Ã§Ã¼k gruplara (mini-batch) bÃ¶ler. Her mini-batch iÃ§in gradyan hesaplanÄ±r ve aÄŸÄ±rlÄ±klar gÃ¼ncellenir.
    Matematiksel FormÃ¼l:
$$w = w - \eta \cdot \nabla_w J(w; X_{batch}, y_{batch})$$
    ğ‘‹ğ‘ğ‘ğ‘¡ğ‘â„, ğ‘¦ğ‘ğ‘ğ‘¡ğ‘â„: Mini-batch verisi.

    AvantajlarÄ±:
        Batch ve SGD yÃ¶ntemlerinin avantajlarÄ±nÄ± birleÅŸtirir.
        Daha dengeli ve daha hÄ±zlÄ± yakÄ±nsama saÄŸlar.
        GPU gibi paralel iÅŸleme birimleri iÃ§in optimize edilebilir.

    DezavantajlarÄ±:
        Mini-batch boyutunun uygun seÃ§ilmesi gerekir (Ã§ok bÃ¼yÃ¼k veya Ã§ok kÃ¼Ã§Ã¼k olursa sorun yaratÄ±r).

# Coordinate Descent

    Coordinate Descent (Koordinat Ä°niÅŸi), optimizasyon ve makine Ã¶ÄŸrenmesi algoritmalarÄ±nda sÄ±kÃ§a kullanÄ±lan bir yÃ¶ntemdir. Temel olarak, Ã§ok deÄŸiÅŸkenli bir fonksiyonun minimum veya maksimum deÄŸerini bulmaya yÃ¶nelik bir iteratif optimizasyon tekniÄŸidir. AdÄ±ndan da anlaÅŸÄ±lacaÄŸÄ± gibi, bu yÃ¶ntem, her seferinde bir parametreyi (koordinat) optimize ederek ilerler.

    Temel Kavramlar
    - Koordinat: Optimizasyon problemi genellikle Ã§oklu deÄŸiÅŸkenlerden oluÅŸur. Bu deÄŸiÅŸkenlerin her birini bir koordinat olarak dÃ¼ÅŸÃ¼nebiliriz. Ã–rneÄŸin, iki deÄŸiÅŸkenli bir fonksiyon 
$$f(x_1, x_2)$$ 
    olsun. Buradaki
$$(x_1, x_2)$$
    deÄŸiÅŸkenleri birer koordinattÄ±r.

    -Ä°niÅŸ (Descent): Ä°niÅŸ, bir fonksiyonun minimumunu bulmak iÃ§in fonksiyonun deÄŸerini azaltma yÃ¶nÃ¼nde bir adÄ±m atmayÄ± ifade eder. Her adÄ±mda, fonksiyonun deÄŸeri azalÄ±r.

    Koordinat Ä°niÅŸi NasÄ±l Ã‡alÄ±ÅŸÄ±r?
        Coordinate Descent algoritmasÄ± ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±r:

        1. BaÅŸlangÄ±Ã§ NoktasÄ±nÄ± SeÃ§me: Ä°lk olarak bir baÅŸlangÄ±Ã§ noktasÄ± seÃ§ilir. Bu nokta, optimizasyonun yapÄ±lacaÄŸÄ± parametre uzayÄ±nÄ±n bir noktasÄ±dÄ±r.

        2. Koordinat SeÃ§imi: ArdÄ±ndan, parametrelerin her birini (veya koordinatlarÄ±) sÄ±rasÄ±yla tek tek optimize ederiz. Yani, f(x_1, x_2, x_3, ..., x_n) fonksiyonu Ã¼zerinde, her bir parametre iÃ§in sÄ±rayla optimize edilir.

        3. Her KoordinatÄ±n Optimize Edilmesi: Bir parametreyi optimize ederken, diÄŸer parametreler sabit tutulur. Bu, bir tÃ¼r tek deÄŸiÅŸkenli optimizasyon problemine indirgenir. Ã–rneÄŸin, x_1 parametresi iÃ§in optimize ederken, x_2, x_3, ..., x_n sabit tutulur.

        4. AdÄ±m AdÄ±m Ä°lerleme: Bu iÅŸlem, her koordinat iÃ§in optimize edilene kadar tekrarlanÄ±r. Her adÄ±mda, sadece bir parametre deÄŸiÅŸtirilir ve sonuÃ§lar bir sonraki adÄ±mda kullanÄ±lÄ±r.

        5. Tekrarlar: YÃ¶ntem, tÃ¼m parametreler optimize edilene kadar (ya da bir durma kriteri saÄŸlanana kadar) devam eder.
